{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Statistical Inference for Autoencoder-based Anomaly Detection after Representation Learning-based Domain Adaptation\nThis example shows how to perform selective inference for Autoencoder-based Anomaly Detection after Representation Learning-based Domain Adaptation using the `pythonsi` library. The method is based on the work by Kiet et al. (2025)[7].\n\n[7] Kiet, T. T., Loi, N. T., & Duy, V. N. L. (2025). Statistical inference for autoencoder-based anomaly detection after representation learning-based domain adaptation. arXiv preprint arXiv:2508.07049.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Tran Tuan Kiet\n\nfrom pythonsi import Pipeline, Data\nfrom pythonsi.domain_adaptation import RepresentationLearningDA\nfrom pythonsi.anomaly_detection import AutoEncoderAD\nfrom pythonsi.test_statistics import AD_DATestStatistic\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom models.wdgrl import Generator\nfrom models.ae import AutoEncoder\nfrom typing import List\nimport torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate Data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def gen_data(mu: float, delta: List[int], n: int, d: int, alpha: float = 0.05):\n    mu = np.full((n, d), mu, dtype=np.float64)\n    noise = np.random.normal(loc=0, scale=1, size=(n, d))\n    X = mu + noise\n    labels = np.zeros(n)\n\n    # 5% of the data is abnormal.\n    # Anomalies are generated by randomly adding deltas to the data.\n    n_anomalies = min(20, int(n * alpha))\n    idx = np.random.choice(n, n_anomalies, replace=False)\n\n    if len(delta) == 0:\n        return X, labels\n\n    split_points = sorted(\n        np.random.choice(range(1, len(idx)), len(delta) - 1, replace=False)\n    )\n    segments = np.split(idx, split_points)\n    for i, segment in enumerate(segments):\n        X[segment] = X[segment] + delta[i]\n    labels[idx] = 1\n    return X, labels, np.identity(n * d)\n\n\nns, nt, d = 150, 25, 32\n\nxs, ys, sigma_s = gen_data(0, [4], ns, d)\nxt, yt, sigma_t = gen_data(2, [4], nt, d)\nplt.scatter(xs[:, 0], xs[:, 1], label=\"Source data\")\nplt.scatter(xt[:, 0], xt[:, 1], label=\"Target data\")\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load pretrained models\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "feature_extractor = Generator(input_dim=d, hidden_dims=[500, 100])\nautoencoder = AutoEncoder(\n    input_dim=100, encoder_hidden_dims=[16, 8, 4, 2], decoder_hidden_dims=[2, 4, 8, 16]\n)\n\nfeature_extractor.load_state_dict(torch.load(\"./models/weights/feature_extractor.pth\"))\nautoencoder.load_state_dict(torch.load(\"./models/weights/autoencoder.pth\"))\n\nfeature_extractor = feature_extractor.to(torch.float32)\nautoencoder = autoencoder.to(torch.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the pipeline\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def STAND_DA() -> Pipeline:\n    xs = Data()\n    xt = Data()\n\n    rl_based_da = RepresentationLearningDA(\n        model=feature_extractor, device=\"cuda\"\n    )  # or \"cpu\"\n    x_tilde = rl_based_da.run(xs=xs, xt=xt)\n\n    autoencoder_ad = AutoEncoderAD(model=autoencoder, device=\"cuda\")  # or \"cpu\"\n    anomaly_indices = autoencoder_ad.run(x=x_tilde, only_target_indices=xt)\n\n    return Pipeline(\n        inputs=(xs, xt),\n        output=anomaly_indices,\n        test_statistic=AD_DATestStatistic(xs=xs, xt=xt),\n    )\n\n\nmy_pipeline = STAND_DA()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run the pipeline\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "anomalies, p_values = my_pipeline(inputs=[xs, xt], covariances=[sigma_s, sigma_t])\n\nprint(\"Anomalies set: \", anomalies)\nprint(\"P-values: \", p_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the p-values\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure()\nplt.bar([str(anomaly) for anomaly in anomalies], p_values)\nplt.xlabel(\"Anomalies index\")\nplt.ylabel(\"P-value\")\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}